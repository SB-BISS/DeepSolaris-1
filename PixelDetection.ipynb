{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* normaliseren per dataset (z-score vs 0-1)\n",
    "* normaliseren per plaatje (z-score vs 0-1)\n",
    "* converteren naar grijswaarden plaatje\n",
    "* histogram test-set converteren naar histogram training set\n",
    "* gabor filter\n",
    "* normaliseren per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ProjectPaths.ProjectPaths at 0x7f017f911940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ProjectPaths import ProjectPaths\n",
    "\n",
    "ProjectPaths.instance(r\"/home/tdjg/Documents/DeepSolaris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_images = np.load(ProjectPaths.instance().file_in_image_dir(\"ds_image_masks.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.load(ProjectPaths.instance().file_in_image_dir(\"ds_images.npy\"))\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_image(image):\n",
    "    avg_kernel = np.ones((3,3), dtype=np.float32)\n",
    "    avg_kernel /= 9\n",
    "    return cv.filter2D(image, -1, avg_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [1., 1., 1.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def window_locations(r = 2, n_channels = 3):\n",
    "    x = [-r, 0, r]\n",
    "    y = [-r, 0, r]\n",
    "    mask = np.zeros((1+2*r,1+2*r))\n",
    "    \n",
    "    for xc in x:\n",
    "        for yc in y:\n",
    "            mask[r + yc, r + xc] = 1.0\n",
    "    return np.tile(mask,(n_channels,1,1)).T\n",
    "    \n",
    "window_mask = window_locations()\n",
    "window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_channels(image):\n",
    "    if image.ndim == 3:\n",
    "        return image.shape[2]\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image, r=2):\n",
    "    #grab the spatial dimensions of the image, along with\n",
    "    # the spatial dimensions of the kernel\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    \n",
    "    kernel = window_locations(r, number_of_channels(image))\n",
    "    (kH, kW) = kernel.shape[:2]\n",
    "\n",
    "    # allocate memory for the output image, taking care to\n",
    "    # \"pad\" the borders of the input image so the spatial\n",
    "    # size (i.e., width and height) are not reduced\n",
    "    pad = (kW - 1) // 2\n",
    "    image = cv.copyMakeBorder(image, pad, pad, pad, pad, cv.BORDER_REPLICATE)\n",
    "    output = np.zeros((iH, iW, 9 *  number_of_channels(image)), dtype=\"float32\")\n",
    "    # loop over the input image, \"sliding\" the kernel across\n",
    "    # each (x, y)-coordinate from left-to-right and top to\n",
    "    # bottom\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            # extract the ROI of the image by extracting the\n",
    "            # *center* region of the current (x, y)-coordinates\n",
    "            # dimensions\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "\n",
    "            # perform the actual selection by taking the\n",
    "            # element-wise multiplicate between the ROI and\n",
    "            # the kernel\n",
    "            k = (roi * kernel)\n",
    "\n",
    "            # store the convolved value in the output (x,y)-\n",
    "            # coordinate of the output image\n",
    "            output[y - pad, x - pad, :] = k[np.nonzero(kernel)]\n",
    "    \n",
    "    # return the output image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def std_image(image):\n",
    "    average = avg_image(image)\n",
    "    x2_min_avg = (image - average) * (image - average);\n",
    "    avg_kernel_3d = np.ones((3, 3, number_of_channels(image)), dtype=np.float32)\n",
    "    avg_kernel_3d /= 9\n",
    "    conv_image = ndimage.convolve(x2_min_avg, avg_kernel_3d, np.float32) \n",
    "    return np.sqrt(conv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    return (image - image.min()) / (image.max() - image.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = std_image(images[0])\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "std.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image):\n",
    "    avg = avg_image(image)\n",
    "    std = std_image(image)\n",
    "    \n",
    "    avg_output2 = extract_features(avg)\n",
    "    std_output2 = extract_features(std)\n",
    "    \n",
    "    avg_output4 = extract_features(avg, 4)\n",
    "    std_output4 = extract_features(std, 4)\n",
    "    return np.concatenate((avg_output2, std_output2, avg_output4, std_output4), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for(images):\n",
    "    feature_list = []\n",
    "    for image in images:\n",
    "        feature_list.append(get_features(image))\n",
    "    return np.array(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = get_features_for(images)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_features = X.reshape(120*75*75, 108)\n",
    "pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_masks = mask_images.reshape(120*75*75)\n",
    "pixel_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "def predict(clf, X_test, y_test):\n",
    "    predictions = clf.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "    print(\"accuracy={}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features = get_features_for([images[-1]])\n",
    "im_features = im_features.reshape(75*75, 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pred = clf.predict(im_features)\n",
    "im_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_image = im_pred.reshape(75, 75)\n",
    "plt.imshow(prediction_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[-1][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ProjectPaths import ProjectPaths\n",
    "from Datasets import Datasets\n",
    "\n",
    "\n",
    "ProjectPaths.instance(r\"/home/tdjg/Documents/DeepSolaris\")\n",
    "ac_dataset = Datasets.datasets()[\"AcMüDüHo\"]\n",
    "train = ac_dataset[0].images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train[8][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features2 = get_features_for([train[8]])\n",
    "im_features2 = im_features2.reshape(75*75, 108)\n",
    "\n",
    "im_pred = clf.predict(im_features2)\n",
    "prediction_image = im_pred.reshape(75, 75)\n",
    "\n",
    "plt.imshow(prediction_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train[8][:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features3 = get_features_for([train[8]])\n",
    "im_features3 = im_features3.reshape(75*75, 108)\n",
    "\n",
    "im_pred = clf.predict(im_features3)\n",
    "prediction_image = im_pred.reshape(75, 75)\n",
    "\n",
    "plt.imshow(normalize_image(prediction_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def reorderMatrix(u):\n",
    "    c1 = np.array([1/3 * math.sqrt(3) for _ in range(3)])\n",
    "    c2 = np.array([1, -1, -1] * c1)\n",
    "    c3 = np.array([0, -1/2 * math.sqrt(2), 1/2 * math.sqrt(2)])\n",
    "    v1 = u.dot(c2)\n",
    "    i1 = np.argmax(v1)\n",
    "    v2 = u.dot(c3)\n",
    "    i2 = np.argmax(v2)\n",
    "    if i1 == 2 and i2 == 1:\n",
    "        temp = u[i1]\n",
    "        u[i1] =  u[i2]\n",
    "        u[i2] = temp\n",
    "    return u\n",
    "\n",
    "def flattenImage(rgbImage):\n",
    "    return rgbImage.reshape(rgbImage.shape[0] * rgbImage.shape[1], 3)\n",
    "\n",
    "def imageMean(image):\n",
    "    return (1 / image.size) * np.sum(image)\n",
    "\n",
    "def centerImage(image):\n",
    "    return image - imageMean(image)\n",
    "\n",
    "def imageCovariance(image1, image2):\n",
    "    return (1 / image1.size) * np.dot(centerImage(image1).ravel(), centerImage(image2).ravel())\n",
    "\n",
    "def rgbImageCovarianceMatrix(rgbImage):\n",
    "    covarianceMatrix = np.zeros([3,3])\n",
    "    for r in range(3):\n",
    "        for c in range (3):\n",
    "            covariance = imageCovariance(rgbImage[:,:,r], rgbImage[:,:,c])\n",
    "            covarianceMatrix[r, c] = covariance\n",
    "            covarianceMatrix[c, r] = covariance\n",
    "    return covarianceMatrix\n",
    "\n",
    "def pca(rgbImage):\n",
    "    covarianceMatrix = rgbImageCovarianceMatrix(rgbImage)\n",
    "    return np.linalg.svd(covarianceMatrix)\n",
    "\n",
    "def pcaTransform(rgbImage):\n",
    "    u,s,v = pca(rgbImage)\n",
    "    imageVector = flattenImage(rgbImage)\n",
    "    transposedVector = imageVector.dot(reorderMatrix(u))\n",
    "    return transposedVector.reshape(rgbImage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_image = pcaTransform(images[0])\n",
    "\n",
    "_, ax = plt.subplots(1,4,figsize=(14,14))\n",
    "ax[0].imshow(images[0])\n",
    "ax[1].imshow(normalize_image(pca_image)[:,:,0])\n",
    "ax[2].imshow(normalize_image(pca_image)[:,:,1])\n",
    "ax[3].imshow(normalize_image(pca_image)[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_images = np.array([pcaTransform(image) for image in images])\n",
    "pca_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = get_features_for(pca_images)\n",
    "pca_pixel_features = pca_features.reshape(120*75*75, 108)\n",
    "pca_pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_X_train, pca_X_test, pca_y_train, pca_y_test = train_test_split(pca_pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(pca_X_train, pca_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clf, pca_X_test, pca_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X = images[0].reshape(75*75,3)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_pca = pca.transform(X).reshape(75,75,3)\n",
    "\n",
    "_, ax = plt.subplots(1,4,figsize=(14,14))\n",
    "ax[0].imshow(images[0][:,:,::-1])\n",
    "ax[1].imshow(normalize_image(im_pca)[:,:,0], cmap='gray')\n",
    "ax[2].imshow(normalize_image(im_pca)[:,:,1], cmap='gray')\n",
    "ax[3].imshow(normalize_image(im_pca)[:,:,2], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_transform(image):\n",
    "    X = image.reshape(image.shape[0]*image.shape[1], image.shape[2])\n",
    "    pca = PCA()\n",
    "    pca.fit(X)\n",
    "    return pca.transform(X).reshape(image.shape)\n",
    "\n",
    "ac_pca_images = np.array([pca_transform(image) for image in ac_dataset[0].images])\n",
    "ac_pca_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_pca_features = get_features_for(ac_pca_images[:120])\n",
    "ac_pca_pixel_features = ac_pca_features.reshape(120*75*75, 108)\n",
    "ac_pca_pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_dataset[0].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(normalize_image(ac_pca_images[i]))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "im_pred = clf.predict(ac_pca_pixel_features)\n",
    "prediction_images = im_pred.reshape(120, 75, 75)\n",
    "\n",
    "_, ax = plt.subplots(4,4, figsize=(14,14))\n",
    "\n",
    "i = 0\n",
    "for r in range(4):\n",
    "    for c in range(4):\n",
    "        ax[r,c].imshow(prediction_images[i])\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[0]\n",
    "mean_per_channel = np.mean(image, axis = (0,1))    \n",
    "mean_per_channel = np.ones((75,75,3)) * mean_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_substracted_image = images[0] - mean_per_channel\n",
    "mean_substracted_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_per_channel = np.std(image, axis = (0,1))\n",
    "std_per_channel = np.ones((75,75,3)) * std_per_channel\n",
    "std_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_image = mean_substracted_image / std_per_channel\n",
    "normalized_image.min(), normalized_image.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_normalize_image(image):\n",
    "    mean_per_channel = np.mean(image, axis = (0,1))    \n",
    "    mean_per_channel = np.ones((75,75,3)) * mean_per_channel\n",
    "    mean_substracted_image = images[0] - mean_per_channel\n",
    "    std_per_channel = np.std(image, axis = (0,1))\n",
    "    std_per_channel = np.ones((75,75,3)) * std_per_channel\n",
    "    return mean_substracted_image / std_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_image = z_normalize_image(images[0])\n",
    "plt.imshow(normalize_image(z_image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_images = np.array([cv.cvtColor(image, cv.COLOR_BGR2GRAY).reshape(image.shape[0], image.shape[1], 1) for image in images])\n",
    "gray_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_images[1][:,:, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-63c325be2176>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgray_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgray_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-0ce147af137a>\u001b[0m in \u001b[0;36mget_features_for\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfeature_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gray_features = get_features_for(gray_images)\n",
    "gray_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_pixel_features = gray_features.reshape(120*75*75, gray_features[:-1])\n",
    "gray_pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(clf, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
