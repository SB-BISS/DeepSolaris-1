{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ProjectPaths.ProjectPaths at 0x7fdbd97cf9b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ProjectPaths import ProjectPaths\n",
    "\n",
    "ProjectPaths.instance(r\"/home/tdjg/Documents/DeepSolaris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_images = np.load(ProjectPaths.instance().file_in_image_dir(\"ds_image_masks.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 75, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.load(ProjectPaths.instance().file_in_image_dir(\"ds_images.npy\"))\n",
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_image(image):\n",
    "    avg_kernel = np.ones((3,3), dtype=np.float32)\n",
    "    avg_kernel /= 9\n",
    "    return cv.filter2D(image, -1, avg_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_locations(r=2):\n",
    "    x = [-r, 0, r]\n",
    "    y = [-r, 0, r]\n",
    "    mask = np.zeros((1+2*r,1+2*r))\n",
    "    \n",
    "    for xc in x:\n",
    "        for yc in y:\n",
    "            mask[r + yc, r + xc] = 1.0\n",
    "    return np.tile(mask,(3,1,1)).T\n",
    "    \n",
    "window_mask = window_locations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image, r=2):\n",
    "    #grab the spatial dimensions of the image, along with\n",
    "    # the spatial dimensions of the kernel\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    \n",
    "    kernel = window_locations(r)\n",
    "    (kH, kW) = kernel.shape[:2]\n",
    "\n",
    "    # allocate memory for the output image, taking care to\n",
    "    # \"pad\" the borders of the input image so the spatial\n",
    "    # size (i.e., width and height) are not reduced\n",
    "    pad = (kW - 1) // 2\n",
    "    image = cv.copyMakeBorder(image, pad, pad, pad, pad, cv.BORDER_REPLICATE)\n",
    "    output = np.zeros((iH, iW, 27), dtype=\"float32\")\n",
    "    # loop over the input image, \"sliding\" the kernel across\n",
    "    # each (x, y)-coordinate from left-to-right and top to\n",
    "    # bottom\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            # extract the ROI of the image by extracting the\n",
    "            # *center* region of the current (x, y)-coordinates\n",
    "            # dimensions\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    "\n",
    "            # perform the actual selection by taking the\n",
    "            # element-wise multiplicate between the ROI and\n",
    "            # the kernel\n",
    "            k = (roi * kernel)\n",
    "\n",
    "            # store the convolved value in the output (x,y)-\n",
    "            # coordinate of the output image\n",
    "            output[y - pad, x - pad, :] = k[np.nonzero(kernel)]\n",
    "    \n",
    "    # return the output image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "def std_image(image):\n",
    "    average = avg_image(image)\n",
    "    x2_min_avg = (image - average) * (image - average);\n",
    "    avg_kernel_3d = np.ones((3, 3, 3), dtype=np.float32)\n",
    "    avg_kernel_3d /= 9\n",
    "    conv_image = ndimage.convolve(x2_min_avg, avg_kernel_3d, np.float32) \n",
    "    return np.sqrt(conv_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    return (image - image.min()) / (image.max() - image.min())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = std_image(images[0])\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "std.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(image):\n",
    "    avg = avg_image(image)\n",
    "    std = std_image(image)\n",
    "    \n",
    "    avg_output2 = extract_features(avg)\n",
    "    std_output2 = extract_features(std)\n",
    "    \n",
    "    avg_output4 = extract_features(avg, 4)\n",
    "    std_output4 = extract_features(std, 4)\n",
    "    return np.concatenate((avg_output2, std_output2, avg_output4, std_output4), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 75, 75, 108)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features_for(images):\n",
    "    feature_list = []\n",
    "    for image in images:\n",
    "        feature_list.append(get_features(image))\n",
    "    return np.array(feature_list)\n",
    "\n",
    "X = get_features_for(images)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675000, 108)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_features = X.reshape(120*75*75, 108)\n",
    "pixel_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(675000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_masks = mask_images.reshape(120*75*75)\n",
    "pixel_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pixel_features, pixel_masks, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tdjg/.virtualenvs/cv/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98     91710\n",
      "         255       0.96      0.94      0.95     43290\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    135000\n",
      "   macro avg       0.96      0.96      0.96    135000\n",
      "weighted avg       0.97      0.97      0.97    135000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9669185185185185"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[89992,  1718],\n",
       "       [ 2748, 40542]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_features = get_features_for([images[1]])\n",
    "im_features = im_features.reshape(75*75, 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5625,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_pred = clf.predict(im_features)\n",
    "im_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdbac153668>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction_image = im_pred.reshape(75, 75)\n",
    "plt.imshow(prediction_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
