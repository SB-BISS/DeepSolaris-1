{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import Xception\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = Xception(False, \"imagenet\")\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(1, activation=\"sigmoid\")(x)\n",
    "model = Model(base_model.input, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Datasets import Datasets\n",
    "\n",
    "dataset_name = \"Bradbury\"\n",
    "dataset = Datasets.datasets()[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "# Add preprocessing\n",
    "train_images = dataset[0].images\n",
    "train_labels  = dataset[0].labels\n",
    "\n",
    "test_images = dataset[1].images\n",
    "test_labels = dataset[1].labels\n",
    "\n",
    "validation_images = dataset[2].images\n",
    "validation_labels = dataset[2].labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3973,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_images.shape\n",
    "validation_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PerformanceMetrics import PerformanceMetrics\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', PerformanceMetrics.precision,\n",
    "                           PerformanceMetrics.recall, PerformanceMetrics.fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_generator = data_generator.flow(train_images, train_labels, batch_size=batch_size)\n",
    "test_generator = test_datagen.flow(test_images, test_labels, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "496/496 [==============================] - 57s 114ms/step - loss: 0.2943 - acc: 0.8409 - precision: 0.8147 - recall: 0.8562 - fmeasure: 0.8178 - val_loss: 0.3780 - val_acc: 0.9094 - val_precision: 0.8497 - val_recall: 0.9930 - val_fmeasure: 0.9145\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.90939, saving model to /media/tim/Data/Work/CBS/Code_hannah/Models/xception_idg_Bradbury_2018-08-31_64_100/xception_idg_Bradbury__01_0.91.hdf5\n",
      "Epoch 2/100\n",
      "496/496 [==============================] - 54s 108ms/step - loss: 0.1121 - acc: 0.9573 - precision: 0.9589 - recall: 0.9569 - fmeasure: 0.9567 - val_loss: 0.1261 - val_acc: 0.9643 - val_precision: 0.9510 - val_recall: 0.9775 - val_fmeasure: 0.9635\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.90939 to 0.96426, saving model to /media/tim/Data/Work/CBS/Code_hannah/Models/xception_idg_Bradbury_2018-08-31_64_100/xception_idg_Bradbury__02_0.96.hdf5\n",
      "Epoch 3/100\n",
      "496/496 [==============================] - 54s 109ms/step - loss: 0.0933 - acc: 0.9659 - precision: 0.9682 - recall: 0.9646 - fmeasure: 0.9655 - val_loss: 0.1343 - val_acc: 0.9638 - val_precision: 0.9480 - val_recall: 0.9816 - val_fmeasure: 0.9638\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.96426\n",
      "Epoch 4/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0821 - acc: 0.9685 - precision: 0.9692 - recall: 0.9682 - fmeasure: 0.9679 - val_loss: 0.0894 - val_acc: 0.9723 - val_precision: 0.9789 - val_recall: 0.9641 - val_fmeasure: 0.9710\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96426 to 0.97231, saving model to /media/tim/Data/Work/CBS/Code_hannah/Models/xception_idg_Bradbury_2018-08-31_64_100/xception_idg_Bradbury__04_0.97.hdf5\n",
      "Epoch 5/100\n",
      "496/496 [==============================] - 55s 111ms/step - loss: 0.0785 - acc: 0.9712 - precision: 0.9702 - recall: 0.9732 - fmeasure: 0.9710 - val_loss: 0.1309 - val_acc: 0.9532 - val_precision: 0.9277 - val_recall: 0.9817 - val_fmeasure: 0.9531\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.97231\n",
      "Epoch 6/100\n",
      "496/496 [==============================] - 56s 113ms/step - loss: 0.0676 - acc: 0.9752 - precision: 0.9770 - recall: 0.9738 - fmeasure: 0.9748 - val_loss: 0.1174 - val_acc: 0.9695 - val_precision: 0.9783 - val_recall: 0.9592 - val_fmeasure: 0.9683\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97231\n",
      "Epoch 7/100\n",
      "496/496 [==============================] - 56s 113ms/step - loss: 0.0668 - acc: 0.9764 - precision: 0.9778 - recall: 0.9749 - fmeasure: 0.9759 - val_loss: 0.1043 - val_acc: 0.9716 - val_precision: 0.9746 - val_recall: 0.9667 - val_fmeasure: 0.9703\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.97231\n",
      "Epoch 8/100\n",
      "496/496 [==============================] - 56s 113ms/step - loss: 0.0628 - acc: 0.9771 - precision: 0.9790 - recall: 0.9753 - fmeasure: 0.9767 - val_loss: 0.0673 - val_acc: 0.9794 - val_precision: 0.9790 - val_recall: 0.9787 - val_fmeasure: 0.9785\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.97231 to 0.97936, saving model to /media/tim/Data/Work/CBS/Code_hannah/Models/xception_idg_Bradbury_2018-08-31_64_100/xception_idg_Bradbury__08_0.98.hdf5\n",
      "Epoch 9/100\n",
      "496/496 [==============================] - 57s 114ms/step - loss: 0.0602 - acc: 0.9784 - precision: 0.9811 - recall: 0.9758 - fmeasure: 0.9780 - val_loss: 0.0795 - val_acc: 0.9746 - val_precision: 0.9683 - val_recall: 0.9795 - val_fmeasure: 0.9735\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.97936\n",
      "Epoch 10/100\n",
      "496/496 [==============================] - 56s 114ms/step - loss: 0.0606 - acc: 0.9786 - precision: 0.9805 - recall: 0.9767 - fmeasure: 0.9782 - val_loss: 0.1104 - val_acc: 0.9663 - val_precision: 0.9456 - val_recall: 0.9882 - val_fmeasure: 0.9659\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.97936\n",
      "Epoch 11/100\n",
      "496/496 [==============================] - 55s 111ms/step - loss: 0.0577 - acc: 0.9797 - precision: 0.9804 - recall: 0.9788 - fmeasure: 0.9792 - val_loss: 0.1154 - val_acc: 0.9597 - val_precision: 0.9340 - val_recall: 0.9869 - val_fmeasure: 0.9591\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.97936\n",
      "Epoch 12/100\n",
      "496/496 [==============================] - 56s 112ms/step - loss: 0.0585 - acc: 0.9790 - precision: 0.9795 - recall: 0.9787 - fmeasure: 0.9786 - val_loss: 0.0727 - val_acc: 0.9786 - val_precision: 0.9893 - val_recall: 0.9668 - val_fmeasure: 0.9777\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.97936\n",
      "Epoch 13/100\n",
      "496/496 [==============================] - 56s 113ms/step - loss: 0.0519 - acc: 0.9810 - precision: 0.9820 - recall: 0.9795 - fmeasure: 0.9804 - val_loss: 0.0633 - val_acc: 0.9786 - val_precision: 0.9715 - val_recall: 0.9854 - val_fmeasure: 0.9780\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.97936\n",
      "Epoch 14/100\n",
      "496/496 [==============================] - 56s 113ms/step - loss: 0.0544 - acc: 0.9810 - precision: 0.9823 - recall: 0.9798 - fmeasure: 0.9806 - val_loss: 0.0900 - val_acc: 0.9773 - val_precision: 0.9839 - val_recall: 0.9699 - val_fmeasure: 0.9765\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.97936\n",
      "Epoch 15/100\n",
      "496/496 [==============================] - 56s 113ms/step - loss: 0.0490 - acc: 0.9830 - precision: 0.9849 - recall: 0.9810 - fmeasure: 0.9826 - val_loss: 0.0616 - val_acc: 0.9801 - val_precision: 0.9766 - val_recall: 0.9836 - val_fmeasure: 0.9796\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.97936 to 0.98012, saving model to /media/tim/Data/Work/CBS/Code_hannah/Models/xception_idg_Bradbury_2018-08-31_64_100/xception_idg_Bradbury__15_0.98.hdf5\n",
      "Epoch 16/100\n",
      "496/496 [==============================] - 56s 114ms/step - loss: 0.0469 - acc: 0.9829 - precision: 0.9833 - recall: 0.9829 - fmeasure: 0.9828 - val_loss: 0.1131 - val_acc: 0.9670 - val_precision: 0.9420 - val_recall: 0.9938 - val_fmeasure: 0.9667\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.98012\n",
      "Epoch 17/100\n",
      "496/496 [==============================] - 56s 114ms/step - loss: 0.0471 - acc: 0.9832 - precision: 0.9853 - recall: 0.9812 - fmeasure: 0.9829 - val_loss: 0.0767 - val_acc: 0.9801 - val_precision: 0.9808 - val_recall: 0.9777 - val_fmeasure: 0.9790\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.98012\n",
      "Epoch 18/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0793 - acc: 0.9819 - precision: 0.9846 - recall: 0.9789 - fmeasure: 0.9814 - val_loss: 0.0636 - val_acc: 0.9789 - val_precision: 0.9873 - val_recall: 0.9693 - val_fmeasure: 0.9778\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.98012\n",
      "Epoch 19/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0484 - acc: 0.9847 - precision: 0.9864 - recall: 0.9827 - fmeasure: 0.9843 - val_loss: 0.0876 - val_acc: 0.9768 - val_precision: 0.9655 - val_recall: 0.9877 - val_fmeasure: 0.9761\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.98012\n",
      "Epoch 20/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0463 - acc: 0.9856 - precision: 0.9861 - recall: 0.9851 - fmeasure: 0.9853 - val_loss: 0.0966 - val_acc: 0.9746 - val_precision: 0.9860 - val_recall: 0.9612 - val_fmeasure: 0.9730\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.98012\n",
      "Epoch 21/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0445 - acc: 0.9844 - precision: 0.9877 - recall: 0.9814 - fmeasure: 0.9843 - val_loss: 0.0706 - val_acc: 0.9791 - val_precision: 0.9780 - val_recall: 0.9784 - val_fmeasure: 0.9779\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.98012\n",
      "Epoch 22/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0528 - acc: 0.9854 - precision: 0.9865 - recall: 0.9845 - fmeasure: 0.9853 - val_loss: 0.0806 - val_acc: 0.9821 - val_precision: 0.9777 - val_recall: 0.9859 - val_fmeasure: 0.9815\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.98012 to 0.98213, saving model to /media/tim/Data/Work/CBS/Code_hannah/Models/xception_idg_Bradbury_2018-08-31_64_100/xception_idg_Bradbury__22_0.98.hdf5\n",
      "Epoch 23/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0415 - acc: 0.9856 - precision: 0.9875 - recall: 0.9835 - fmeasure: 0.9853 - val_loss: 0.0771 - val_acc: 0.9819 - val_precision: 0.9773 - val_recall: 0.9852 - val_fmeasure: 0.9809\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.98213\n",
      "Epoch 24/100\n",
      "496/496 [==============================] - 55s 110ms/step - loss: 0.0427 - acc: 0.9854 - precision: 0.9873 - recall: 0.9835 - fmeasure: 0.9851 - val_loss: 0.1049 - val_acc: 0.9753 - val_precision: 0.9920 - val_recall: 0.9575 - val_fmeasure: 0.9740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00024: val_acc did not improve from 0.98213\n",
      "Epoch 25/100\n",
      "496/496 [==============================] - 54s 108ms/step - loss: 0.0408 - acc: 0.9872 - precision: 0.9897 - recall: 0.9849 - fmeasure: 0.9870 - val_loss: 0.0745 - val_acc: 0.9829 - val_precision: 0.9778 - val_recall: 0.9868 - val_fmeasure: 0.9820\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.98213 to 0.98288, saving model to /media/tim/Data/Work/CBS/Code_hannah/Models/xception_idg_Bradbury_2018-08-31_64_100/xception_idg_Bradbury__25_0.98.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5302a508d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from ProjectPaths import ProjectPaths\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model_name = \"xception_idg_{}\".format(dataset_name)\n",
    "\n",
    "checkpoint_dir = ProjectPaths.checkpoint_dir_for(model_name, batch_size, epochs)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "file_in_checkpoint_dir = ProjectPaths.file_in_checkpoint_dir(model_name, batch_size,\n",
    "                                                                 epochs,  model_name +\n",
    "                                                                 \"__{epoch:02d}_{val_acc:.2f}.hdf5\")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(patience=10)\n",
    "model_checkpoint_callback = ModelCheckpoint(file_in_checkpoint_dir, monitor='val_acc', verbose=True,\n",
    "                                                save_weights_only=True,\n",
    "                                                save_best_only=True)\n",
    "\n",
    "log_dir = os.path.join(ProjectPaths.log_dir(), model_name)\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=0,  write_graph=False, write_images=False)\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(train_labels) // batch_size, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[early_stopping_callback, model_checkpoint_callback, tensorboard_callback],\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=len(test_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Bradbury"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31776/31776 [==============================] - 14s 431us/step\n",
      "3973/3973 [==============================] - 2s 433us/step\n",
      "3973/3973 [==============================] - 2s 432us/step\n",
      "       loss       acc  precision    recall  fmeasure\n",
      "0  0.036073  0.989520   0.989427  0.989660  0.989373\n",
      "1  0.074477  0.982884   0.977841  0.986821  0.981953\n",
      "2  0.086786  0.978102   0.975374  0.981704  0.978224\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_eval = model.evaluate(train_images, train_labels, batch_size)\n",
    "test_eval = model.evaluate(test_images, test_labels, batch_size)\n",
    "validation_eval = model.evaluate(validation_images, validation_labels, batch_size)\n",
    "\n",
    "np_model_evaluations = np.array([train_eval, test_eval, validation_eval])\n",
    "\n",
    "evaluations = pd.DataFrame(np_model_evaluations, columns=model.metrics_names)\n",
    "print(evaluations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[412,  45],\n",
       "       [154, 323]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "validation_predictions = model.predict(validation_images, batch_size) > 0.5\n",
    "confusion_matrix(validation_labels, validation_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.73      0.90      0.81       457\n",
      "        1.0       0.88      0.68      0.76       477\n",
      "\n",
      "avg / total       0.80      0.79      0.78       934\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What happened to the metrics above?? Bug in Hannah's metrics?\n",
    "print(classification_report(validation_labels, validation_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Aachen\n",
    "\n",
    "Evaluation of the Aachen dataset with the model trained on Bradbury California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3357, 75, 75, 3) (374, 75, 75, 3) (934, 75, 75, 3)\n",
      "(4665, 75, 75, 3) (4665,)\n"
     ]
    }
   ],
   "source": [
    "ac_dataset = Datasets.datasets()[\"AcMüDüHo\"]\n",
    "\n",
    "train_images = ac_dataset[0].images\n",
    "train_labels = ac_dataset[0].labels\n",
    "\n",
    "test_images = ac_dataset[1].images\n",
    "test_labels = ac_dataset[1].labels\n",
    "\n",
    "validation_images = ac_dataset[2].images\n",
    "validation_labels = ac_dataset[2].labels\n",
    "\n",
    "eval_images = np.concatenate((train_images, test_images, validation_images), axis=0)\n",
    "eval_labels = np.concatenate((train_labels, test_labels, validation_labels), axis=0)\n",
    "\n",
    "\n",
    "print(train_images.shape, test_images.shape, validation_images.shape)\n",
    "print(eval_images.shape, eval_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2101,  233],\n",
       "       [ 822, 1509]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_predictions = model.predict(eval_images, batch_size) > 0.5\n",
    "confusion_matrix(eval_labels, eval_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.72      0.90      0.80      2334\n",
      "        1.0       0.87      0.65      0.74      2331\n",
      "\n",
      "avg / total       0.79      0.77      0.77      4665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(eval_labels, eval_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Fresno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3646, 75, 75, 3) (1022, 75, 75, 3) (1022, 75, 75, 3)\n",
      "(5690, 75, 75, 3) (5690,)\n"
     ]
    }
   ],
   "source": [
    "fresno_dataset = Datasets.datasets()[\"Fresno\"]\n",
    "\n",
    "train_images = fresno_dataset[0].images\n",
    "train_labels = fresno_dataset[0].labels\n",
    "\n",
    "test_images = fresno_dataset[1].images\n",
    "test_labels = fresno_dataset[1].labels\n",
    "\n",
    "validation_images = fresno_dataset[2].images\n",
    "validation_labels = fresno_dataset[2].labels\n",
    "\n",
    "fresno_eval_images = np.concatenate((train_images, test_images, validation_images), axis=0)\n",
    "fresno_eval_labels = np.concatenate((train_labels, test_labels, validation_labels), axis=0)\n",
    "\n",
    "\n",
    "print(train_images.shape, test_images.shape, validation_images.shape)\n",
    "print(fresno_eval_images.shape, fresno_eval_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2809,   36],\n",
       "       [  19, 2826]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fresno_eval_predictions = model.predict(fresno_eval_images, batch_size) > 0.5\n",
    "confusion_matrix(fresno_eval_labels, fresno_eval_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      2845\n",
      "          1       0.99      0.99      0.99      2845\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(fresno_eval_labels, fresno_eval_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
